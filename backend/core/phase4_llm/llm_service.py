"""
Phase 4: LLM Reasoning & Question Generation
Use LLM to understand project and generate intelligent interview questions
"""
from typing import List, Dict, Any
from pydantic import BaseModel
from groq import Groq
from loguru import logger
from config import settings


class ProjectSummary(BaseModel):
    """Project summary generated by LLM"""
    title: str
    description: str
    purpose: str
    tech_stack_summary: str
    key_features: List[str]
    workflow_description: str
    complexity_level: str  # beginner, intermediate, advanced


class InterviewQuestion(BaseModel):
    """Interview question"""
    question_text: str
    question_type: str  # why, what, how, where
    difficulty: str  # easy, medium, hard
    context: str  # Related code/file
    expected_keywords: List[str]
    evaluation_criteria: List[str]


class LLMService:
    """LLM Service for project understanding and question generation"""
    
    def __init__(self):
        self.client = Groq(api_key=settings.GROQ_API_KEY)
        self.model = settings.MODEL_NAME
        self.temperature = settings.TEMPERATURE
    
    def generate_project_summary(
        self,
        readme_content: str,
        tech_stack: List[str],
        frameworks: List[str],
        main_modules: List[str],
        sample_code: str = ""
    ) -> ProjectSummary:
        """Generate comprehensive project summary"""
        
        prompt = f"""You are an expert technical interviewer analyzing a candidate's GitHub project.

## Repository Information:

### README:
{readme_content[:2000]}

### Tech Stack:
{', '.join(tech_stack)}

### Frameworks:
{', '.join(frameworks)}

### Main Modules:
{', '.join(main_modules)}

### Sample Code:
{sample_code[:1000]}

## Task:
Analyze this project and provide a comprehensive summary including:

1. **Project Title**: A clear, concise title
2. **Description**: What the project does (2-3 sentences)
3. **Purpose**: Why this project exists, what problem it solves
4. **Tech Stack Summary**: Brief overview of technologies used and why
5. **Key Features**: List 3-5 main features or capabilities
6. **Workflow**: How the application works (user flow or system architecture)
7. **Complexity Level**: Assess as beginner, intermediate, or advanced

Return the analysis in JSON format with these keys:
- title
- description
- purpose
- tech_stack_summary
- key_features (array)
- workflow_description
- complexity_level
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert technical project analyst. Return ONLY valid JSON with no markdown or extra text."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature
            )
            
            content = response.choices[0].message.content.strip()
            
            # Extract JSON if wrapped in markdown code blocks
            if content.startswith("```"):
                content = content.split("```json")[-1] if "```json" in content else content.split("```")[-1]
                content = content.split("```")[0].strip()
            
            import json
            summary_dict = json.loads(content)
            
            return ProjectSummary(**summary_dict)
            
        except Exception as e:
            logger.error(f"Error generating project summary: {e}")
            logger.debug(f"Response content: {response.choices[0].message.content if 'response' in locals() else 'N/A'}")
            # Return default summary
            return ProjectSummary(
                title="Project Analysis",
                description="A software project",
                purpose="Project purpose not determined",
                tech_stack_summary=f"Uses {', '.join(tech_stack[:3])}",
                key_features=["Feature analysis pending"],
                workflow_description="Workflow analysis pending",
                complexity_level="intermediate"
            )
    
    def generate_interview_questions(
        self,
        project_summary: ProjectSummary,
        role_type: str,
        code_context: List[Dict[str, Any]],
        required_skills: List[str]
    ) -> List[InterviewQuestion]:
        """Generate contextual interview questions"""
        
        # Prepare code context
        context_text = "\n\n".join([
            f"### {ctx['metadata'].get('file_path', 'Unknown')}:\n{ctx['content'][:500]}"
            for ctx in code_context[:5]
        ])
        
        prompt = f"""You are an expert technical interviewer for a {role_type} internship role.

## Project Summary:
**Title**: {project_summary.title}
**Description**: {project_summary.description}
**Purpose**: {project_summary.purpose}
**Tech Stack**: {project_summary.tech_stack_summary}
**Complexity**: {project_summary.complexity_level}

## Key Features:
{chr(10).join([f"- {feature}" for feature in project_summary.key_features])}

## Code Context:
{context_text}

## Required Skills for {role_type}:
{', '.join(required_skills)}

## Task:
Generate {settings.MAX_QUESTIONS} intelligent interview questions about THIS SPECIFIC PROJECT.

### Question Types to Include:
1. **WHY Questions** (2-3): Understanding reasoning and decisions
   - Why did you choose X technology?
   - Why is this approach used?

2. **WHAT Questions** (2-3): Understanding components and functionality
   - What does this module do?
   - What is the purpose of X feature?

3. **HOW Questions** (2-3): Understanding implementation
   - How does X feature work?
   - How did you handle Y challenge?

4. **WHERE Questions** (1-2): Understanding architecture
   - Where is X logic implemented?
   - Where would you add Y feature?

### Requirements:
- Questions MUST be specific to the candidate's code
- Mix difficulty: {settings.MIN_QUESTIONS//2} easy/medium, rest medium/hard
- Focus on {role_type} role skills
- Include context/code snippets where relevant
- Provide expected keywords for evaluation

Return as JSON array with objects containing:
- question_text
- question_type (why/what/how/where)
- difficulty (easy/medium/hard)
- context (relevant code/file reference)
- expected_keywords (array of 3-5 keywords)
- evaluation_criteria (array of 2-3 criteria)
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert technical interviewer. Return ONLY valid JSON with no markdown or extra text."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature
            )
            
            content = response.choices[0].message.content.strip()
            
            # Extract JSON if wrapped in markdown code blocks
            if content.startswith("```"):
                content = content.split("```json")[-1] if "```json" in content else content.split("```")[-1]
                content = content.split("```")[0].strip()
            
            import json
            data = json.loads(content)
            
            # Extract questions array (handle different response formats)
            # Check if data is already a list/array
            if isinstance(data, list):
                questions_data = data
            elif isinstance(data, dict):
                questions_data = data.get('questions', [])
                # Check if the entire response is an array
                if not questions_data and 'items' in data:
                    questions_data = data['items']
            else:
                questions_data = []
            
            questions = []
            for q_data in questions_data[:settings.MAX_QUESTIONS]:
                try:
                    questions.append(InterviewQuestion(**q_data))
                except Exception as e:
                    logger.warning(f"Skipping invalid question: {e}")
                    continue
            
            logger.success(f"Generated {len(questions)} interview questions")
            return questions
            
        except Exception as e:
            logger.error(f"Error generating questions: {e}")
            # Return fallback questions
            return self._generate_fallback_questions(project_summary, role_type)
    
    def _generate_fallback_questions(self, project_summary: ProjectSummary, role_type: str) -> List[InterviewQuestion]:
        """Generate fallback questions if LLM fails"""
        return [
            InterviewQuestion(
                question_text=f"What is the main purpose of your {project_summary.title} project?",
                question_type="what",
                difficulty="easy",
                context="Project README",
                expected_keywords=["purpose", "goal", "solve", "user"],
                evaluation_criteria=["Clear explanation", "Understanding of project goal"]
            ),
            InterviewQuestion(
                question_text=f"Why did you choose {project_summary.tech_stack_summary.split()[1] if len(project_summary.tech_stack_summary.split()) > 1 else 'this technology'} for this project?",
                question_type="why",
                difficulty="medium",
                context="Technology choice",
                expected_keywords=["performance", "features", "suitable", "familiar"],
                evaluation_criteria=["Technical reasoning", "Decision making"]
            ),
            InterviewQuestion(
                question_text="How does the main workflow of your application function?",
                question_type="how",
                difficulty="medium",
                context="Application workflow",
                expected_keywords=["user", "process", "flow", "steps"],
                evaluation_criteria=["System understanding", "Architecture knowledge"]
            ),
            InterviewQuestion(
                question_text=f"What are the key features you implemented in this project?",
                question_type="what",
                difficulty="easy",
                context="Feature implementation",
                expected_keywords=["feature", "functionality", "capability"],
                evaluation_criteria=["Feature knowledge", "Implementation understanding"]
            ),
            InterviewQuestion(
                question_text="How would you improve or scale this project if given more time?",
                question_type="how",
                difficulty="hard",
                context="Future improvements",
                expected_keywords=["scalability", "optimization", "improvement", "feature"],
                evaluation_criteria=["Critical thinking", "Forward planning"]
            ),
            InterviewQuestion(
                question_text="Where is the main business logic implemented in your codebase?",
                question_type="where",
                difficulty="medium",
                context="Code architecture",
                expected_keywords=["module", "file", "folder", "component"],
                evaluation_criteria=["Code organization understanding", "Architecture awareness"]
            )
        ]
    
    def generate_questions_from_job_description(
        self,
        job_description: str,
        role_type: str,
        required_skills: List[str],
        preferred_skills: List[str] = None
    ) -> List[InterviewQuestion]:
        """Generate 10 standardized interview questions from job description
        
        These questions will be the same for all candidates applying to this job.
        They focus on role requirements, skills, and general technical knowledge.
        """
        
        preferred_skills = preferred_skills or []
        
        prompt = f"""You are an expert technical interviewer for a {role_type} internship role.

## Job Description:
{job_description}

## Required Skills:
{', '.join(required_skills)}

## Preferred Skills:
{', '.join(preferred_skills) if preferred_skills else 'Not specified'}

## Task:
Generate EXACTLY 10 interview questions for this job role. These questions will be asked to ALL candidates applying for this position, so they should:
- Be general enough to work for any candidate
- Focus on the role requirements and skills
- Test understanding of technologies mentioned in the JD
- Cover both theoretical knowledge and practical scenarios
- Be fair and consistent for all applicants

### Question Distribution:
1. **WHY Questions** (2): Understanding motivations and reasoning
   - Why are you interested in this role?
   - Why is [specific skill from JD] important for this position?

2. **WHAT Questions** (3): Understanding concepts and technologies
   - What is [technology/concept from JD]?
   - What are the key responsibilities of a {role_type}?
   - What experience do you have with [skill from JD]?

3. **HOW Questions** (3): Understanding implementation and problem-solving
   - How would you approach [scenario from JD]?
   - How do you ensure [quality aspect] in your work?
   - How would you handle [technical challenge]?

4. **WHERE Questions** (2): Understanding application and architecture
   - Where would you use [technology from JD]?
   - Where have you applied [skill from JD] in past projects?

### Difficulty Distribution:
- 3 Easy questions (basic concepts, motivation)
- 5 Medium questions (technical understanding, experience)
- 2 Hard questions (problem-solving, architecture)

### Requirements:
- Questions must be specific to the job requirements
- Include context from the job description
- Provide expected keywords for evaluation (5-7 keywords per question)
- Include evaluation criteria (3-4 criteria per question)

Return as JSON array with EXACTLY 10 objects containing:
- question_text
- question_type (why/what/how/where)
- difficulty (easy/medium/hard)
- context (reference to JD requirement)
- expected_keywords (array of 5-7 keywords)
- evaluation_criteria (array of 3-4 criteria)
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert technical interviewer. Return ONLY valid JSON array with EXACTLY 10 question objects. No markdown, no extra text."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7  # Slightly lower temperature for consistency
            )
            
            content = response.choices[0].message.content.strip()
            
            # Extract JSON if wrapped in markdown code blocks
            if content.startswith("```"):
                content = content.split("```json")[-1] if "```json" in content else content.split("```")[-1]
                content = content.split("```")[0].strip()
            
            import json
            data = json.loads(content)
            
            # Extract questions array
            if isinstance(data, list):
                questions_data = data
            elif isinstance(data, dict):
                questions_data = data.get('questions', data.get('items', []))
            else:
                questions_data = []
            
            questions = []
            for q_data in questions_data[:10]:  # Ensure exactly 10 questions
                try:
                    questions.append(InterviewQuestion(**q_data))
                except Exception as e:
                    logger.warning(f"Skipping invalid question: {e}")
                    continue
            
            # Ensure we have exactly 10 questions
            if len(questions) < 10:
                logger.warning(f"Only generated {len(questions)} questions, adding fallback questions")
                questions.extend(self._generate_fallback_jd_questions(role_type, required_skills)[len(questions):10])
            
            logger.success(f"Generated {len(questions)} JD-based interview questions")
            return questions[:10]  # Return exactly 10 questions
            
        except Exception as e:
            logger.error(f"Error generating JD questions: {e}")
            # Return fallback questions
            return self._generate_fallback_jd_questions(role_type, required_skills)
    
    def _generate_fallback_jd_questions(self, role_type: str, required_skills: List[str]) -> List[InterviewQuestion]:
        """Generate fallback JD-based questions if LLM fails"""
        skills_str = ', '.join(required_skills[:3]) if required_skills else "relevant technologies"
        
        return [
            InterviewQuestion(
                question_text=f"Why are you interested in this {role_type} position?",
                question_type="why",
                difficulty="easy",
                context="Motivation and interest",
                expected_keywords=["interest", "passion", "learn", "grow", "opportunity"],
                evaluation_criteria=["Clear motivation", "Alignment with role", "Genuine interest"]
            ),
            InterviewQuestion(
                question_text=f"What experience do you have with {skills_str}?",
                question_type="what",
                difficulty="medium",
                context="Technical skills",
                expected_keywords=["experience", "project", "worked", "used", "implemented"],
                evaluation_criteria=["Relevant experience", "Technical depth", "Practical application"]
            ),
            InterviewQuestion(
                question_text=f"What are the key responsibilities of a {role_type} developer?",
                question_type="what",
                difficulty="easy",
                context="Role understanding",
                expected_keywords=["development", "coding", "testing", "collaboration", "deployment"],
                evaluation_criteria=["Role awareness", "Industry knowledge", "Comprehensive understanding"]
            ),
            InterviewQuestion(
                question_text="How do you ensure code quality in your projects?",
                question_type="how",
                difficulty="medium",
                context="Quality practices",
                expected_keywords=["testing", "review", "standards", "documentation", "best practices"],
                evaluation_criteria=["Quality awareness", "Professional practices", "Attention to detail"]
            ),
            InterviewQuestion(
                question_text="How would you approach learning a new technology required for this role?",
                question_type="how",
                difficulty="medium",
                context="Learning ability",
                expected_keywords=["documentation", "practice", "tutorial", "project", "community"],
                evaluation_criteria=["Learning strategy", "Adaptability", "Self-motivation"]
            ),
            InterviewQuestion(
                question_text=f"How do you handle debugging and troubleshooting in {role_type} development?",
                question_type="how",
                difficulty="medium",
                context="Problem-solving",
                expected_keywords=["debug", "logs", "tools", "systematic", "reproduce"],
                evaluation_criteria=["Debugging skills", "Problem-solving approach", "Tool knowledge"]
            ),
            InterviewQuestion(
                question_text=f"Where would you use {required_skills[0] if required_skills else 'modern frameworks'} in production applications?",
                question_type="where",
                difficulty="medium",
                context="Practical application",
                expected_keywords=["application", "use case", "implementation", "production", "scalable"],
                evaluation_criteria=["Practical knowledge", "Real-world understanding", "Architecture awareness"]
            ),
            InterviewQuestion(
                question_text="Where have you demonstrated strong problem-solving skills in your past work?",
                question_type="where",
                difficulty="medium",
                context="Past experience",
                expected_keywords=["challenge", "solution", "problem", "resolved", "innovative"],
                evaluation_criteria=["Problem-solving evidence", "Critical thinking", "Impact demonstration"]
            ),
            InterviewQuestion(
                question_text=f"Why is collaboration important in {role_type} development teams?",
                question_type="why",
                difficulty="easy",
                context="Teamwork",
                expected_keywords=["teamwork", "communication", "collaboration", "shared", "together"],
                evaluation_criteria=["Team awareness", "Communication skills", "Collaborative mindset"]
            ),
            InterviewQuestion(
                question_text=f"How would you design a scalable architecture for a {role_type} application?",
                question_type="how",
                difficulty="hard",
                context="System design",
                expected_keywords=["scalable", "architecture", "distributed", "performance", "reliability"],
                evaluation_criteria=["System design knowledge", "Scalability understanding", "Best practices"]
            )
        ]


# Service instance
llm_service = LLMService()

